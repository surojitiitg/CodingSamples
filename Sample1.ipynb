{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5QZAtzmuqK9",
        "outputId": "c1d4afd4-7a24-421f-afb9-2fe575f9d401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wixDXT28uqK-"
      },
      "source": [
        "# Check Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_maNRmJuqK_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset import MNISTPatch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfwK4kG7uqK_",
        "outputId": "edd8152d-73a4-478b-c511-217ba0e68783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input image torch.Size([10, 16, 7, 7])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 144x144 with 16 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 144x144 with 16 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = MNISTPatch(n_device=16,root='./data', train=True)\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=False)\n",
        "x,y = next(iter(loader))\n",
        "print('input image',x.shape)\n",
        "for bdx in range(2):\n",
        "    fig,axs = plt.subplots(4,4,figsize=(2,2), constrained_layout=True)\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            axs[i,j].imshow(x[bdx,i*4+j,:,:],cmap='gray')\n",
        "    for ax in axs.flat:\n",
        "        ax.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6jUGQCVuqLA",
        "outputId": "e8dce14d-a1fe-4993-bbf0-2c9570b147ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input image torch.Size([10, 4, 14, 14])\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJgAAACYCAYAAAAYwiAhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFoUlEQVR4nO3dMUiUfxzHcTVp0NPSxYYIsUEpkltM0CAiwknRxEFqCmtJdBRHsSDRQQpDdDFoDhIcdCh1UERBXZLWKBwasjQULW348x9+fn/ePZ738bk736/t++333P14+vTw67nfPZd9cHCQBajkhD0BZDYCBikCBikCBikCBikCBqncWH+YnZ3NPYysrKyDg4NsX5/z85+jzk9WFlcwiBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSBEwSMX8XuRZcO7cOae+cOFC4GOLi4vjjmlvbze9vLw80ysvLze9p0+fOvXAwIAZ09raano7OztO/eLFCzOmp6fHTlaAKxikCBikCBik0nINduXKFac+f/68GVNbW2t6t27dMr2ioiKnbm5uDjyP79+/Bx4bz9evX03v5cuXTt3U1GTGbG5umt7q6qpTz8zMnHB2ieMKBikCBikCBikCBqnsWM/JT4UHrEWjUdObnp526uPcHE2Q9wFr+/v7CZ2f/f1903v06JHpbW1txX2t9fV10/vx44dTf/78+RizOz4eQIfQEDBIETBIETBIpfwi37djYXFx0anLysrU0/AuYufn58352djYcOo7d+6Y43Z3d03vFP6jIsMiH6EhYJAiYJBK+TWYT2Njo1PX19ebMcvLy6b36tWruK+9srJietFo1LvGiEQi5vz8/v3bqa9fv26O6+zsNL0nT57EnVuqYg2G0BAwSBEwSBEwSKXlIv+wwsJC0/NtJR4ZGTG9trY2p3748KEZ8/btW37OLwYW+QgNAYMUAYMUAYNUWn4v8rBfv34FGvfz58+4Yx4/fhz4fXNy7L9P33bos4wrGKQIGKQIGKQIGKQy4k5+UPn5+aY3MTHh1Ldv3/Yd6r1TXVdXZ87P1NRUYpNLY9zJR2gIGKQIGKTO1BrM5+rVq07t2zIdiUS8a4wvX76Y8/Px40enXlpaMscNDQ2ZXqy/h1THGgyhIWCQImCQImCQirnIB06KKxikCBikCBikCBikCBikYu7JPwsfFR3m+z2gd+/eeT8K2dzcNOenoKAg7nt0d3eb3ps3b0zP94jyVMRHRQgNAYMUAYMUAYPUmd8PFsRRi9gbN26Y8zM4OOjUd+/eDfQew8PDpvfs2TOn/vbtW6DXOm0s8hEaAgYpAgYp1mABHLXG8J2fixcvOnVDQ4M5bmxszPdapvfhwwenDrqeO22swRAaAgYpAgYpAgYpFvkBHGeRH8Te3p7p5ebajS1//vxx6nv37pkx09PTiUwhqVjkIzQEDFIEDFIEDFIZ8RjzsFRWVppeS0uLU9+8edOM8S3ofT59+uTUs7Ozx5hdauAKBikCBikCBikCBqkzv8gvLy936o6OjsDHTk5Omt6lS5cSmsffv39N7/D3ItPxd5C4gkGKgEGKgEEqY3dT+NZCDx48ML329nanLi0t9b3cUbsFEjo/vkeb9/b2mt74+HgiL3/q2E2B0BAwSBEwSBEwSKXljdaSkhKnvnbtmhnz+vVr06uoqJDN6X8LCwtO3dfXZ8a8f//e9NLxJmoQXMEgRcAgRcAgRcAglVKL/OLiYtMbHR01vWg06tRlZWVJm8Pc3Jzp1dTUeMf6nkh9eIfF9vZ2ciaWpriCQYqAQYqAQerUdlNUV1ebXldXl1NXVVWZMZcvX07WFLzrocMP7X3+/LkZs7W1ldRnU2QadlMgNAQMUgQMUgQMUqd2o/X+/fum57tRGcTa2ppT+7YW+74G1t/fb3obGxsJzQHBcAWDFAGDFAGDFAGDVMZ+LzKZkv2U6UzDnXyEhoBBioBBioBBioBBioBBioBBioBBioBBioBBioBBioBBioBBKuZuCuCkuIJBioBBioBBioBBioBBioBB6h96nmyLar7mjAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 144x144 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 144x144 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = MNISTPatch(n_device=4,root='./data', train=True)\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=False)\n",
        "x,y = next(iter(loader))\n",
        "print('input image',x.shape)\n",
        "for bdx in range(2):\n",
        "    fig,axs = plt.subplots(2,2,figsize=(2,2), constrained_layout=True)\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            axs[i,j].imshow(x[bdx,i*2+j,:,:],cmap='gray')\n",
        "    for ax in axs.flat:\n",
        "        ax.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx55vExjuqLA"
      },
      "source": [
        "# Model and message passing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOvHIjXzuqLB"
      },
      "source": [
        "## Single Unit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ei-dpGGeuqLB"
      },
      "outputs": [],
      "source": [
        "from model import DevicePerceptron, MessageConcat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORB4jK3DuqLB",
        "outputId": "b6d83b1b-5c2b-48e8-da06-a6e38e0e5fcd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.randint(0, 5, (1,)).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb3x3HuguqLB",
        "outputId": "ce4aa993-2390-457a-81b7-96fa290f8d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weight torch.Size([3, 2, 2])\n",
            "bias torch.Size([3, 2])\n"
          ]
        }
      ],
      "source": [
        "dmlp = DevicePerceptron(n_device=3,d_in=2,d_out=2)\n",
        "ms = MessageConcat(max_num_elements=3)\n",
        "\n",
        "\n",
        "print('weight',dmlp.state_dict()['weight'].shape)\n",
        "print('bias',dmlp.state_dict()['bias'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPYt5pe9uqLC",
        "outputId": "2548485a-bc1a-4f80-ccb6-5201a70e7137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('weight', tensor([[[1., 0.],\n",
            "         [0., 1.]],\n",
            "\n",
            "        [[2., 0.],\n",
            "         [0., 2.]],\n",
            "\n",
            "        [[3., 0.],\n",
            "         [0., 3.]]])), ('bias', tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]]))])\n"
          ]
        }
      ],
      "source": [
        "# change weight and bias for sanity check\n",
        "# check bias later\n",
        "with torch.no_grad():\n",
        "    for i in range(3):\n",
        "        dmlp.weight[i,:,:] = torch.eye(2)*(i+1)\n",
        "        dmlp.bias[i,:] = 0\n",
        "print(dmlp.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ppkPBk5uqLC",
        "outputId": "d2095d48-62f7-4620-ca62-05e36692f8f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[  1.,   1.],\n",
            "         [ 10.,  10.],\n",
            "         [100., 100.]]])\n",
            "\n",
            " each server output\n",
            "tensor([[[  1.,   1.],\n",
            "         [ 20.,  20.],\n",
            "         [300., 300.]]], grad_fn=<ReluBackward0>)\n",
            "\n",
            " sending message\n",
            "data at server 0 tensor([[  1.,   1.,  20.,  20., 300., 300.]], grad_fn=<SliceBackward0>)\n",
            "data at server 1 tensor([[20., 20.,  0.,  0.,  0.,  0.]], grad_fn=<SliceBackward0>)\n",
            "data at server 2 tensor([[300., 300.,  20.,  20.,   0.,   0.]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# One Sample\n",
        "data = torch.Tensor([[1,1],[10,10],[100,100]]).unsqueeze(0)\n",
        "print(data)\n",
        "\n",
        "print('\\n each server output')\n",
        "data = dmlp(data)\n",
        "print(data)\n",
        "\n",
        "print('\\n sending message')\n",
        "edge_index = torch.tensor([[0, 0],\n",
        "                           [1, 0],\n",
        "                           [2, 0],\n",
        "                           [1, 1],\n",
        "                           [2, 2],\n",
        "                           [1, 2]], dtype=torch.long).T\n",
        "\n",
        "data = ms(data,edge_index)\n",
        "for i in range(3):\n",
        "    print(f'data at server {i}',data[:,i,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKLze9O3uqLD",
        "outputId": "e1eb740e-8912-4fd7-a495-4a27c95ae7e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[  1.,   1.],\n",
            "         [ 10.,  10.],\n",
            "         [100., 100.]],\n",
            "\n",
            "        [[  3.,   3.],\n",
            "         [ 30.,  30.],\n",
            "         [ 60.,  60.]]])\n",
            "\n",
            " each server output\n",
            "tensor([[[  1.,   1.],\n",
            "         [ 20.,  20.],\n",
            "         [300., 300.]],\n",
            "\n",
            "        [[  3.,   3.],\n",
            "         [ 60.,  60.],\n",
            "         [180., 180.]]], grad_fn=<CloneBackward0>)\n",
            "\n",
            " sending message\n",
            "data at server 0 tensor([[  1.,   1.,  20.,  20., 300., 300.],\n",
            "        [  3.,   3.,  60.,  60., 180., 180.]], grad_fn=<SliceBackward0>)\n",
            "data at server 1 tensor([[20., 20.,  0.,  0.,  0.,  0.],\n",
            "        [60., 60.,  0.,  0.,  0.,  0.]], grad_fn=<SliceBackward0>)\n",
            "data at server 2 tensor([[300., 300.,  20.,  20.,   0.,   0.],\n",
            "        [180., 180.,  60.,  60.,   0.,   0.]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Batch\n",
        "bs = 2\n",
        "data = torch.Tensor([[[1,1],[10,10],[100,100]],[[3,3],[30,30],[60,60]]])\n",
        "print(data)\n",
        "\n",
        "print('\\n each server output')\n",
        "data = dmlp(data).contiguous()\n",
        "print(data)\n",
        "\n",
        "print('\\n sending message')\n",
        "edge_index = torch.tensor([[0, 0],\n",
        "                           [1, 0],\n",
        "                           [2, 0],\n",
        "                           [1, 1],\n",
        "                           [2, 2],\n",
        "                           [1, 2]], dtype=torch.long).T\n",
        "edge_index_batch = []\n",
        "for i in range(bs):\n",
        "    edge_index_batch.append(edge_index.clone()+3*i)\n",
        "edge_index = torch.cat(edge_index_batch,dim=1)\n",
        "data = ms(data,edge_index)\n",
        "for i in range(3):\n",
        "    print(f'data at server {i}',data[:,i,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ1Cig9FuqLD"
      },
      "source": [
        "## Full Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahDTIsMquqLD"
      },
      "outputs": [],
      "source": [
        "from model import MVFL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a96LMCGuqLD"
      },
      "outputs": [],
      "source": [
        "model = MVFL(16,repeat=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Plc3QZdbuqLD"
      },
      "outputs": [],
      "source": [
        "def get_batch_edge_index_MVFL(drop_mode, drop_rate, n_device, bs, return_device_valid=False):\n",
        "    # TODO: find a better way to avoid using for loop\n",
        "    # get edge_index for one sample\n",
        "    edge_index = []\n",
        "    n_receiver, n_sender = n_device, n_device\n",
        "\n",
        "    if drop_mode == 'comm':\n",
        "        device_valid = list(range(n_device))\n",
        "        for i in range(n_sender):\n",
        "            for j in range(n_receiver):\n",
        "                # i - sender\n",
        "                # j - receiver\n",
        "                if i == j:\n",
        "                    edge_index.append([j, i])\n",
        "                else:\n",
        "                    if torch.rand(1) > drop_rate:\n",
        "                        edge_index.append([j, i])\n",
        "    elif drop_mode == 'device':\n",
        "        device_valid = []\n",
        "        for i in range(n_sender):\n",
        "            rand_check = torch.rand(1)\n",
        "            if rand_check > drop_rate:\n",
        "                device_valid.append(i)\n",
        "            for j in range(n_receiver):\n",
        "                # i - sender\n",
        "                # j - receiver\n",
        "                if i == j:\n",
        "                    edge_index.append([j, i])\n",
        "                else:\n",
        "                    if rand_check > drop_rate:\n",
        "                        edge_index.append([j, i])\n",
        "    else:\n",
        "        raise ValueError('drop_mode not recognized')\n",
        "    edge_index = torch.Tensor(edge_index).T\n",
        "    # repeat for  all samples in the batch\n",
        "    edge_index_batch = []\n",
        "    for i in range(bs):\n",
        "        edge_index_batch.append(edge_index.clone() + n_device*i)\n",
        "    edge_index = torch.cat(edge_index_batch, dim=1).long()\n",
        "    if return_device_valid:\n",
        "        return edge_index, device_valid\n",
        "    else:\n",
        "        return edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuiMVmZ3uqLE",
        "outputId": "4572e2e3-89e4-4b26-dc24-e3d312bf7882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 80])\n",
            "torch.Size([2, 1280])\n"
          ]
        }
      ],
      "source": [
        "print(get_batch_edge_index(drop_mode='comm',drop_rate=1,n_device=16,bs=5).shape)\n",
        "print(get_batch_edge_index(drop_mode='comm',drop_rate=0,n_device=16,bs=5).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7VN8JETuqLE",
        "outputId": "ec4b9907-ccd1-49a1-ee5e-d0649a25292e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output torch.Size([15, 16, 10])\n",
            "pred torch.Size([15, 16])\n"
          ]
        }
      ],
      "source": [
        "data = torch.randn(15,16,7,7)\n",
        "edge_index = torch.tensor([[0, 0],\n",
        "                           [1, 0],\n",
        "                           [2, 0],\n",
        "                           [1, 1],\n",
        "                           [2, 2],\n",
        "                           [1, 2]], dtype=torch.long).T\n",
        "edge_index,device_valid = get_batch_edge_index(drop_mode='comm',drop_rate=0.5,n_device=16,bs=len(data),return_device_valid=True)\n",
        "output = model(data,edge_index)\n",
        "output = output[:,device_valid,:]\n",
        "print('output',output.shape)\n",
        "pred = output.argmax(dim=-1)\n",
        "print('pred',pred.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0TZdE1TuqLE",
        "outputId": "ba0b8f2c-f4be-43a5-c28a-e348df582b68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output torch.Size([15, 8, 10])\n",
            "pred torch.Size([15, 8])\n"
          ]
        }
      ],
      "source": [
        "data = torch.randn(15,16,7,7)\n",
        "edge_index = torch.tensor([[0, 0],\n",
        "                           [1, 0],\n",
        "                           [2, 0],\n",
        "                           [1, 1],\n",
        "                           [2, 2],\n",
        "                           [1, 2]], dtype=torch.long).T\n",
        "edge_index,device_valid = get_batch_edge_index(drop_mode='device',drop_rate=0.5,n_device=16,bs=len(data),return_device_valid=True)\n",
        "output = model(data,edge_index)\n",
        "output = output[:,device_valid,:]\n",
        "print('output',output.shape)\n",
        "pred = output.argmax(dim=-1)\n",
        "print('pred',pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-a39cNVDuqLE"
      },
      "outputs": [],
      "source": [
        "def get_batch_edge_index_VFL(drop_mode, drop_rate, n_device, bs):\n",
        "    # TODO: find a better way to avoid using for loop\n",
        "    # get edge_index for one sample\n",
        "    edge_index = []\n",
        "    n_sender = n_device\n",
        "\n",
        "    server_idx = torch.randint(0, n_device, (1,)).item()\n",
        "    for i in range(n_sender):\n",
        "        # i - sender\n",
        "        # j - receiver\n",
        "        if i == j:\n",
        "            edge_index.append([server_idx, i])\n",
        "        else:\n",
        "            if torch.rand(1) > drop_rate:\n",
        "                edge_index.append([server_idx, i])\n",
        "\n",
        "\n",
        "    edge_index = torch.Tensor(edge_index).T\n",
        "    # repeat for  all samples in the batch\n",
        "    edge_index_batch = []\n",
        "    for i in range(bs):\n",
        "        edge_index_batch.append(edge_index.clone() + n_device*i)\n",
        "    edge_index = torch.cat(edge_index_batch, dim=1).long()\n",
        "\n",
        "    return edge_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2FttE72uqLE",
        "outputId": "7805b86c-7daf-4484-8710-3a98f25eeaa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 5])\n",
            "torch.Size([2, 80])\n"
          ]
        }
      ],
      "source": [
        "print(get_batch_edge_index_VFL(drop_mode='comm',drop_rate=1,n_device=16,bs=5).shape)\n",
        "print(get_batch_edge_index_VFL(drop_mode='comm',drop_rate=0,n_device=16,bs=5).shape)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}